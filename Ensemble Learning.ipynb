{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dea4bb5b-ce2a-4704-a325-d5fe45e26c25",
   "metadata": {},
   "source": [
    "##### 1.Can we use Bagging for regression problems?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35cf2ec-3fc0-4d87-bd8e-8dcefba81101",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans -Yes, Bagging can be used for regression problems, commonly with models like Decision Trees.\n",
    "#e.g. Bagging Regressor in scikit-learn. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd279c7-19e8-4cb6-893d-0d704bbd2c27",
   "metadata": {},
   "source": [
    "##### 2. What is the difference b/w multiple model training and single model training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd5f587-3ad2-471b-ab0d-92e02baf31aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans -    Single Model Training: Trains one model on the dataset.\n",
    "#Multiple Model Training: Trains multiple models (e.g., ensemble methods) to improve accuracy and robustness. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b02f4c-b99c-44d5-bf72-dcc191863efc",
   "metadata": {},
   "source": [
    "##### 3. Explain the concept of feature randomness in Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226d0834-3c7b-4101-bd06-dc0a6c33d773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans - Feature randomness in Random Forest means that each tree in the forest selects a random subset of features at each split, rather than considering all features.\n",
    "#This helps in reducing overfitting and making the model more robust."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8555b42d-d357-491c-80f6-8b4ff012c869",
   "metadata": {},
   "source": [
    "##### 4. What is OOB(out-of-Bag) Score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d76331-be2e-4491-8238-1d37d1403720",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans -OOB (Out-of-Bag) Score is the accuracy of a Random Forest model measured using data not included in the bootstrap sample for training each tree.\n",
    "#It acts as a built-in validation metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf1ad5d-3497-453e-8a95-11e4bf863744",
   "metadata": {},
   "source": [
    "##### 5.How can you measure the importance of features in a Random Forest model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c63f3f1-e952-4a7c-b29f-85307d1558bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans -Feature importance in Random Forest can be measured using:\n",
    "#Gini Importance (Mean Decrease in Impurity) – Measures how much each feature reduces impurity in splits.\n",
    "#Permutation Importance – Measures the drop in model performance when a feature’s values are randomly shuffled. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3280bf-e34c-473f-8527-eb5f99339af3",
   "metadata": {},
   "source": [
    "##### 6.Explain the working principle of a Bagging Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f80eee-5424-46b2-b555-d57077a97b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans -A Bagging Classifier works by training multiple models (usually the same type) on different random subsets of the data (with replacement). \n",
    "#The final prediction is made by averaging (for regression) or majority voting (for classification) from all models.\n",
    "#This reduces variance and improves accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6ad24d-fcfb-45a2-96df-1bff424cf9c4",
   "metadata": {},
   "source": [
    "##### 7. How do you evaluate a Bagging Classifier's performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b52713-cd66-417d-9fcf-d16372117d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans- We can evaluate a Bagging Classifier's performance using:\n",
    "#Accuracy Score – Measures overall correctness.\n",
    "#Confusion Matrix – Analyzes true/false positives and negatives.\n",
    "#Precision, Recall, F1-Score – Evaluates class-wise performance.\n",
    "#ROC-AUC Score – Measures classification quality for imbalanced data.\n",
    "#Cross-Validation – Tests model stability on different data splits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cf2b86-03f4-461e-a5a9-6655bb47a1d0",
   "metadata": {},
   "source": [
    "##### 8. How does a Bagging Regressor work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f76f81-7b2d-4a49-a522-32b28f23e603",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans -A Bagging Regressor trains multiple regression models on different random subsets of the data (with replacement). \n",
    "#The final prediction is made by averaging the outputs of all models, reducing variance and improving stability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ed8bf4-5d97-42e0-9251-42bd934ecf74",
   "metadata": {},
   "source": [
    "##### 9. What is the main advantage of ensemble techniques?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4bbda7-ae36-40e3-8096-03bc8a305618",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans - The main advantage of ensemble techniques is :-\n",
    "#They combine multiple models to improve accuracy, reduce variance, and enhance robustness compared to individual models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb7e8f1-8e5d-46b9-acb8-736637f39952",
   "metadata": {},
   "source": [
    "##### 10.What is the main challenge of ensemble methods?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5dddd4-e80d-4c38-a152-3bafe1b7f9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans - The main challenge of ensemble methods is increased computational cost and complexity, \n",
    "#as they require training multiple models and managing their combination effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc122c9-c959-4a5d-80ab-f7de258503ec",
   "metadata": {},
   "source": [
    "##### 11. Explain the key idea behind ensemble techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e2c477-dbdb-41e4-bc11-76c62cefbd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans -The key idea behind ensemble techniques is to combine multiple models to improve overall performance. \n",
    "#By aggregating predictions, they reduce errors, increase accuracy, and enhance model stability compared to a single model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7689cd-5ccc-4168-9f7c-877b523d2d4a",
   "metadata": {},
   "source": [
    "##### 12. What is a Random Forest Classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36795f27-a192-420f-8c37-b480ceb17bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans -A Random Forest Classifier is an ensemble learning method.\n",
    "#It builds multiple decision trees on random subsets of data.\n",
    "#Combines predictions using majority voting for classification "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828aacee-4846-464b-9b7b-783a9f7fa0cf",
   "metadata": {},
   "source": [
    "##### 13.What are the main types of ensemble techniques?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169b10d0-dfec-4633-aeb0-f65fa618d6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans - The main types of ensemble techniques are:\n",
    "#Bagging – Trains multiple models on random subsets and averages predictions (e.g., Random Forest).\n",
    "#Boosting – Sequentially improves weak models by focusing on misclassified data (e.g., AdaBoost).\n",
    "#Stacking – Combines multiple model predictions using a meta-model.\n",
    "#Voting – Uses majority voting (classification) or averaging (regression) for final prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06d9292-61bc-45d6-83c1-f7729942021e",
   "metadata": {},
   "source": [
    "##### 14.What is ensemble learning in machine learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c7c694-c0c5-483d-8ad3-41b93b5107da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans - Ensemble learning combines multiple models to improve performance.\n",
    "#It helps reduce variance, bias, and overfitting.\n",
    "#Improves accuracy and robustness compared to a single model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65bc40d-99da-4fbd-952d-68ffc6cd8544",
   "metadata": {},
   "source": [
    "##### 15.When should we avoid using ensemble methods?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a703c341-47e5-4cc3-8941-cb4a30ca5a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans - Ensemble methods should be avoided when:\n",
    "#The dataset is small, as a single model may perform well.\n",
    "#Computational resources are limited, since ensembles require more processing power.\n",
    "#Interpretability is important, as ensembles are harder to explain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9215a88-e575-41a9-949f-28584fc822a2",
   "metadata": {},
   "source": [
    "##### 16.How does Bagging help in reducing overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b33d8f3-9e91-494d-92b8-86f05500d686",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans -Bagging reduces overfitting by:\n",
    "#Training multiple models on different random subsets of data.\n",
    "#Averaging predictions (for regression) or using majority voting (for classification), which smooths out errors.\n",
    "#Reducing model variance, making predictions more stable "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254cdf48-4385-494f-a705-87498e63b9f3",
   "metadata": {},
   "source": [
    "##### 17.Why is Random Forest bettern than a Single Decision Tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980742c9-89e3-412f-bac6-b370246a1c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans -Random Forest is better than a single Decision Tree because:\n",
    "#Reduces Overfitting – Combines multiple trees, making it more generalizable.\n",
    "#Improves Accuracy – Aggregates predictions, reducing errors.\n",
    "#Handles Missing Data – Can work with incomplete datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84860b60-9a1f-497d-b3de-5e36a71b1385",
   "metadata": {},
   "source": [
    "##### 18.What is the role of bootstrap sampling in Bagging?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4449ae7-d342-4be1-9099-3c86366e0bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans - The role of bootstrap sampling in Bagging is to:\n",
    "#Create random subsets of the original data by sampling with replacement.\n",
    "#Ensure diversity among models by training each on different data samples.\n",
    "#Reduce overfitting by averaging multiple models’ predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054fa415-0d55-4d6d-9864-053bc9280933",
   "metadata": {},
   "source": [
    "##### 19. What are the some real-world applications of ensemble techniques?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f72e3f-0fda-49e6-8076-c77f50d07e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans -Some real-world applications of ensemble techniques include:\n",
    "#Fraud Detection – Identifies fraudulent transactions in banking.\n",
    "#Medical Diagnosis – Improves disease prediction and classification.\n",
    "#Stock Market Prediction – Enhances financial forecasting models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06929db3-3911-4862-a8ca-41933ed23365",
   "metadata": {},
   "source": [
    "##### 20. what is the difference between Bagging and Boosting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7cdd18-daf2-4090-9004-017197af9eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans - Bagging trains models independently to reduce variance (e.g., Random Forest).\n",
    "#Boosting trains models sequentially to reduce bias (e.g., AdaBoost, XGBoost).\n",
    "#Bagging uses parallel training, while Boosting uses sequential training.\n",
    "#Bagging combines models using averaging or voting.\n",
    "#Boosting gives higher weight to misclassified data for better learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e643064-5376-4dca-8809-bf86455e752c",
   "metadata": {},
   "source": [
    "## practical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4607966a-4594-4a7b-bd0f-d8de5ea1397c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28888228-e7c6-4a16-894c-339b76a02d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2654b894-a589-456b-9410-3245b8472487",
   "metadata": {},
   "source": [
    "##### 21.Train a Bagging Classifier using Decision Trees on a sample dataset and Print model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e767fb5-86cf-436b-8cef-16f2bf3911d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create sample dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=5, random_state=42)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Bagging Classifier\n",
    "model = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and print accuracy\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7ce6f8-4292-45a7-b79d-71b07ceea0f7",
   "metadata": {},
   "source": [
    "##### 22.Train a Bagging Regressor using Decision Trees and evaluate using Mean Squared Error(MSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ed9d9dc-0b9e-4c54-a59c-8756a373d44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 429.81140885042754\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "# Create sample dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=5, random_state=42)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Bagging Regressor\n",
    "model = BaggingRegressor(estimator=DecisionTreeRegressor(), n_estimators=10, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate using MSE\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Mean Squared Error (MSE):\", mean_squared_error(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7170466a-6ab9-4497-9c41-0d4e7665af1a",
   "metadata": {},
   "source": [
    "##### 23.Train a Random Forest Classifier on the Breast Cancer dataset and Print importance scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33b16ae4-d714-4faf-b3d8-e9ae191e05a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worst concave points       0.162381\n",
      "worst perimeter            0.125161\n",
      "worst radius               0.099323\n",
      "mean perimeter             0.093043\n",
      "worst concavity            0.078470\n",
      "mean radius                0.069829\n",
      "mean concavity             0.068267\n",
      "mean concave points        0.063024\n",
      "area error                 0.061231\n",
      "worst compactness          0.038555\n",
      "worst texture              0.022781\n",
      "worst area                 0.022102\n",
      "mean texture               0.019670\n",
      "mean area                  0.012190\n",
      "mean smoothness            0.010596\n",
      "worst symmetry             0.008409\n",
      "worst smoothness           0.006101\n",
      "mean symmetry              0.004658\n",
      "texture error              0.004624\n",
      "worst fractal dimension    0.004595\n",
      "mean fractal dimension     0.004367\n",
      "concavity error            0.003355\n",
      "radius error               0.003323\n",
      "concave points error       0.003097\n",
      "fractal dimension error    0.002280\n",
      "perimeter error            0.002220\n",
      "symmetry error             0.002184\n",
      "smoothness error           0.001763\n",
      "compactness error          0.001695\n",
      "mean compactness           0.000707\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "# Load dataset\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Train Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Print feature importance\n",
    "importance = pd.Series(model.feature_importances_, index=data.feature_names)\n",
    "print(importance.sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4eb1d3b-b31c-485b-a9eb-ecbfc45ab41f",
   "metadata": {},
   "source": [
    "##### 24.Train a Random Forest Regressor and compare its performance with a single Decision Tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "998a974c-f749-4365-a55b-ad92141966c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MSE: 1773.2175689143996\n",
      "Decision Tree MSE: 3153.0882008564386\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "\n",
    "# Create dataset\n",
    "X, y = make_regression(n_samples=500, n_features=5, random_state=42)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train models\n",
    "rf = RandomForestRegressor(n_estimators=10, random_state=42)\n",
    "dt = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict and compare performance\n",
    "rf_pred = rf.predict(X_test)\n",
    "dt_pred = dt.predict(X_test)\n",
    "\n",
    "print(\"Random Forest MSE:\", mean_squared_error(y_test, rf_pred))\n",
    "print(\"Decision Tree MSE:\", mean_squared_error(y_test, dt_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524827d6-3398-4e01-8848-e55fa817cff8",
   "metadata": {},
   "source": [
    "##### 25.Compute the Out - of - Bag(OOB) Score for a Random Forest Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "386f2f86-fb51-43cb-8cec-70e1237e02c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB Score: 0.932\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create dataset\n",
    "X, y = make_classification(n_samples=500, n_features=5, random_state=42)\n",
    "\n",
    "# Train Random Forest with OOB score\n",
    "model = RandomForestClassifier(n_estimators=10, oob_score=True, random_state=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Print OOB score\n",
    "print(\"OOB Score:\", model.oob_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e60caa-571a-4ce2-8631-81c05bd6b1f0",
   "metadata": {},
   "source": [
    "##### 26.Train a Bagging Classifier using SVM as a base estimatore and print accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f0f153a9-a42c-4940-8384-09a20b71353d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.93\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create dataset\n",
    "X, y = make_classification(n_samples=500, n_features=5, random_state=42)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Bagging Classifier with SVM\n",
    "model = BaggingClassifier(estimator=SVC(), n_estimators=10, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and print accuracy\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdb8e94-90a0-4ca4-b5b0-69b1a7afa545",
   "metadata": {},
   "source": [
    "##### 27.Train a Random Forest Classifier with different numbers of trees and compare accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6bc6cf42-11dd-4ce6-bc19-4c588f5a0ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trees: 5, Accuracy: 0.95\n",
      "Trees: 10, Accuracy: 0.94\n",
      "Trees: 50, Accuracy: 0.96\n",
      "Trees: 100, Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create dataset\n",
    "X, y = make_classification(n_samples=500, n_features=5, random_state=42)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Random Forest with different tree counts\n",
    "for n_trees in [5, 10, 50, 100]:\n",
    "    model = RandomForestClassifier(n_estimators=n_trees, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"Trees: {n_trees}, Accuracy: {accuracy_score(y_test, y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f493194-952d-4158-a84a-f1ec9433f187",
   "metadata": {},
   "source": [
    "##### 28. Train a Bagging Classifier using Logistic Regression as a base estimator and print AUC Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "52697cd3-4431-4261-b950-e572bfc25048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.9498548693824442\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# Create dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=5, random_state=42)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Bagging Classifier with Logistic Regression\n",
    "model = BaggingClassifier(estimator=LogisticRegression(), n_estimators=10, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and print AUC Score\n",
    "y_pred_prob = model.predict_proba(X_test)[:, 1]  \n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_pred_prob))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd544b81-b100-473b-99a4-288ad7416410",
   "metadata": {},
   "source": [
    "##### 29.Train a Random Forest Regressor and analyze feature importance scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5070a8df-f16d-435f-991f-063c835bf2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance:\n",
      " 3    0.521903\n",
      "0    0.360654\n",
      "2    0.061088\n",
      "4    0.045855\n",
      "1    0.010500\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "\n",
    "# Create dataset\n",
    "X, y = make_regression(n_samples=500, n_features=5, random_state=42)\n",
    "\n",
    "# Train Random Forest Regressor\n",
    "model = RandomForestRegressor(n_estimators=10, random_state=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Print feature importance scores\n",
    "importance = pd.Series(model.feature_importances_)\n",
    "print(\"Feature Importance:\\n\", importance.sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7866242-f76e-40d3-a61e-6138c3b8d6ae",
   "metadata": {},
   "source": [
    "##### 30.Train an ensemble model using both Bagging and Random Forest and compare accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6052e396-04dd-4fd0-a788-3ec37e07b053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier Accuracy: 0.9071428571428571\n",
      "Random Forest Classifier Accuracy: 0.8785714285714286\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create dataset\n",
    "X, y = make_classification(n_samples=700, n_features=5, random_state=42)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Bagging Classifier\n",
    "bagging_model = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42)\n",
    "bagging_model.fit(X_train, y_train)\n",
    "\n",
    "# Train Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and compare accuracy\n",
    "bagging_acc = accuracy_score(y_test, bagging_model.predict(X_test))\n",
    "rf_acc = accuracy_score(y_test, rf_model.predict(X_test))\n",
    "\n",
    "print(\"Bagging Classifier Accuracy:\", bagging_acc)\n",
    "print(\"Random Forest Classifier Accuracy:\", rf_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde87dc6-04e2-47d4-9032-3ac8cf7bf0d9",
   "metadata": {},
   "source": [
    "##### 31.Train a Random Forest and tune hyperparameters using GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "862db497-4bb4-464a-b40c-f121e2c6fd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 10, 'n_estimators': 100}\n",
      "Best Accuracy: 0.9516666666666665\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create dataset\n",
    "X, y = make_classification(n_samples=1500, n_features=5, random_state=42)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define Random Forest model and hyperparameter grid\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "param_grid = {'n_estimators': [10, 50, 100], 'max_depth': [None, 5, 10]}\n",
    "\n",
    "# Grid Search\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and accuracy\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Accuracy:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2a76a0-76e5-4bfe-8657-85dbd9d7b1a6",
   "metadata": {},
   "source": [
    "##### 32.Train a Bagging Regressor with different numbers of base estimators and compare performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "33cef138-6152-4c16-ae70-a321ad4151e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimators: 5, MSE: 2055.5184997584856\n",
      "Estimators: 10, MSE: 1713.318608798281\n",
      "Estimators: 50, MSE: 1606.9810547544093\n",
      "Estimators: 100, MSE: 1480.8014550556222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "# Create dataset\n",
    "X, y = make_regression(n_samples=500, n_features=5, random_state=42)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Bagging Regressor with different numbers of base estimators\n",
    "for n_estimators in [5, 10, 50, 100]:\n",
    "    model = BaggingRegressor(estimator=DecisionTreeRegressor(), n_estimators=n_estimators, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"Estimators: {n_estimators}, MSE: {mean_squared_error(y_test, y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59da5009-f1f7-42e3-9294-11c3f12ecacf",
   "metadata": {},
   "source": [
    "##### 33.Train a Random Forest Classifier and analyze misclassified samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "145f57c5-18aa-4692-993c-23d986bfc22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: [ 2 11 49 72 90 91]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Create dataset\n",
    "X, y = make_classification(n_samples=500, n_features=5, random_state=42)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Random Forest\n",
    "model = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and find misclassified samples\n",
    "y_pred = model.predict(X_test)\n",
    "misclassified_indices = np.where(y_pred != y_test)[0]\n",
    "print(\"Misclassified samples:\", misclassified_indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bad64ab-3c71-4d17-8873-83aaac8f7f56",
   "metadata": {},
   "source": [
    "##### 34. Train a Bagging Classifier and compare its performance with a Single Decision Tree Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cdf08056-d87e-4751-b140-0f387f8d2eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier Accuracy: 0.895\n",
      "Single Decision Tree Accuracy: 0.8825\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Create dataset\n",
    "X, y = make_classification(n_samples=2000, n_features=5, random_state=42)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train models\n",
    "bagging_model = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42)\n",
    "tree_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "bagging_model.fit(X_train, y_train)\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and compare accuracy\n",
    "print(\"Bagging Classifier Accuracy:\", accuracy_score(y_test, bagging_model.predict(X_test)))\n",
    "print(\"Single Decision Tree Accuracy:\", accuracy_score(y_test, tree_model.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1490367b-5505-472c-a0f5-e921211fadd9",
   "metadata": {},
   "source": [
    "##### 35.Train a Random Forest Classifier and visualize the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "50ab7a43-20f5-48a8-adcd-e6b88aa7f6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Create dataset\n",
    "X, y = make_classification(n_samples=500, n_features=5, random_state=42)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Random Forest\n",
    "model = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and visualize confusion matrix\n",
    "cm = confusion_matrix(y_test, model.predict(X_test))\n",
    "\n",
    "sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt=\"d\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00aca15d-e335-4eab-b8db-6c4004433891",
   "metadata": {},
   "source": [
    "##### 36.Train a Stacking Classifier using Decision Trees, SVM, and Logistic Regression, and compare accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "da16bfe2-735d-47bc-a74d-147b55862fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier Accuracy: 0.94\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create dataset\n",
    "X, y = make_classification(n_samples=500, n_features=5, random_state=42)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define base models\n",
    "base_models = [\n",
    "    ('dt', DecisionTreeClassifier()),\n",
    "    ('svm', SVC(probability=True)),\n",
    "    ('lr', LogisticRegression())\n",
    "]\n",
    "\n",
    "# Define stacking classifier\n",
    "stack_model = StackingClassifier(estimators=base_models, final_estimator=LogisticRegression())\n",
    "stack_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and print accuracy\n",
    "y_pred = stack_model.predict(X_test)\n",
    "print(\"Stacking Classifier Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2017b000-4a92-4ed4-b26e-bed032f84c9b",
   "metadata": {},
   "source": [
    "##### 37.Train a Random Forest Classifier and print the top 5 most important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "290f6f43-eae1-42b3-9a0f-c65b6e88f22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Most Important Features:\n",
      " 0    0.509162\n",
      "2    0.215633\n",
      "3    0.145819\n",
      "4    0.111307\n",
      "1    0.018079\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create dataset\n",
    "X, y = make_classification(n_samples=500, n_features=5, random_state=42)\n",
    "\n",
    "# Train Random Forest\n",
    "model = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Print top 5 important features\n",
    "importance = pd.Series(model.feature_importances_).sort_values(ascending=False)\n",
    "print(\"Top 5 Most Important Features:\\n\", importance.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea34e45-1b88-4857-a3d6-8c065d8df689",
   "metadata": {},
   "source": [
    "##### 38.Train a Bagging Classifier and evaluate performance using Precision,Recall and F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f74fa433-a01a-4d4e-971e-1f8e267b71a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.92\n",
      "Recall: 0.9787234042553191\n",
      "F1-Score: 0.9484536082474226\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Create dataset\n",
    "X, y = make_classification(n_samples=500, n_features=5, random_state=42)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Bagging Classifier\n",
    "model = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate metrics\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1-Score:\", f1_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0aacd8-6ce8-488c-bae3-3efc893e80b5",
   "metadata": {},
   "source": [
    "##### 39.Train a Random Forest Classifier and analyze the effect of max_depth on accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "84dcede9-8b5b-42ca-8887-a183bfc6892e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth: None, Accuracy: 0.92\n",
      "Max Depth: 5, Accuracy: 0.915\n",
      "Max Depth: 10, Accuracy: 0.92\n",
      "Max Depth: 20, Accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Create dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=6, random_state=42)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Analyze effect of max_depth\n",
    "for depth in [None, 5, 10, 20]:\n",
    "    model = RandomForestClassifier(n_estimators=50, max_depth=depth, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"Max Depth: {depth}, Accuracy: {accuracy_score(y_test, y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee737b4-1f44-4f6c-a1f3-b8944cbf4fc1",
   "metadata": {},
   "source": [
    "##### 40.Train a Bagging Regressor using different base estimators(DecisionTree and KNeighbors) and compare performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d3a95c3c-225c-49c5-acff-38019831fb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree - MSE: 1713.318608798281\n",
      "KNeighbors - MSE: 1648.963589404266\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "# Create dataset\n",
    "X, y = make_regression(n_samples=500, n_features=5, random_state=42)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train models\n",
    "estimators = {\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"KNeighbors\": KNeighborsRegressor()\n",
    "}\n",
    "\n",
    "for name, estimator in estimators.items():\n",
    "    model = BaggingRegressor(estimator=estimator, n_estimators=10, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"{name} - MSE: {mean_squared_error(y_test, y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41898b3d-da56-4990-a45b-f93898356e89",
   "metadata": {},
   "source": [
    "##### 41.Train a Random Forest Classifier and evaluate its performance using ROC-AUC Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4ddc6f60-0905-456e-9252-075ade2de6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC Score: 0.9791795665634675\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Create dataset\n",
    "X, y = make_classification(n_samples=1800, n_features=7, random_state=42)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Random Forest\n",
    "model = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and compute ROC-AUC Score\n",
    "y_pred_prob = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
    "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_pred_prob))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81baeb1d-dbcb-4dc5-ac85-2d26380fb940",
   "metadata": {},
   "source": [
    "##### 42.Train a Bagging Classifier and evaluate its performance using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b52d5caf-80dc-4bdd-a290-34902f7421d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.88   0.8875 0.89   0.905  0.92  ]\n",
      "Mean Accuracy: 0.8965\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Create dataset\n",
    "X, y = make_classification(n_samples=2000, n_features=4, random_state=42)\n",
    "\n",
    "# Train Bagging Classifier with Cross-Validation\n",
    "model = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42)\n",
    "scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Print cross-validation results\n",
    "print(\"Cross-Validation Accuracy Scores:\", scores)\n",
    "print(\"Mean Accuracy:\", scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3dd959-52c3-405b-961f-610359e813f0",
   "metadata": {},
   "source": [
    "##### 43.Train a Random Forest Classifier and plot the Precision - Recall curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "25ad4768-14c7-4e47-a1c6-aadf6b9da498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "\n",
    "# Create dataset\n",
    "X, y = make_classification(n_samples=500, n_features=5, random_state=42)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Random Forest\n",
    "model = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities\n",
    "y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Compute precision-recall curve\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_prob)\n",
    "\n",
    "# Plot the curve\n",
    "plt.plot(recall, precision, marker='.')\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e36a10c-cc39-4af2-b87c-72b0eb761236",
   "metadata": {},
   "source": [
    "##### 44.Train a Stacking Classifier with Random Forest and Logistic Regression and compare accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "694e2524-3ed5-4568-985b-11c078f6df3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create dataset\n",
    "X, y = make_classification(n_samples=500, n_features=5, random_state=42)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define base models\n",
    "base_models = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=50, random_state=42))\n",
    "]\n",
    "\n",
    "# Define stacking classifier\n",
    "stack_model = StackingClassifier(estimators=base_models, final_estimator=LogisticRegression())\n",
    "stack_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and print accuracy\n",
    "y_pred = stack_model.predict(X_test)\n",
    "print(\"Stacking Classifier Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079bb1eb-4f38-4640-864b-f6861daf3770",
   "metadata": {},
   "source": [
    "##### 45.Train a Bagging Regressor with different levels of bootstrap samples and compare performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1315bc3d-bb89-4c22-b3d1-71b732c29706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap=True, MSE: 1713.318608798281\n",
      "Bootstrap=False, MSE: 3126.501666699227\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "# Create dataset\n",
    "X, y = make_regression(n_samples=500, n_features=5, random_state=42)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Bagging Regressor with different bootstrap sample levels\n",
    "for bootstrap in [True, False]:  # True enables bootstrap, False disables it\n",
    "    model = BaggingRegressor(estimator=DecisionTreeRegressor(), n_estimators=10, bootstrap=bootstrap, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"Bootstrap={bootstrap}, MSE: {mean_squared_error(y_test, y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231f5427-e243-4586-bb23-e3512a467930",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
